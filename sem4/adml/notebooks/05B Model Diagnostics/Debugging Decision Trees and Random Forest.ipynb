{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">**Disclaimer**: The author of this exercise has been fired because he made a fundamental machine learning mistake when creating this Jupyter Notebook.</font>\n",
    "\n",
    "> Your task is to find the mistake the data scientist made and submit the answer on ILIAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Decision Trees and Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In todays exercise we want to predict car prices from the AutoScout24 dataset by using a Decision Tree and Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "We are going to use the AutoScout24 dataset and apply the feature engineering we have developed in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cars.csv\")\n",
    "\n",
    "df['Age'] = df.Year-1984\n",
    "df['Brand'] = df.Name.str.split(' ').map(lambda x: x[0])\n",
    "df.drop(['Name', 'Registration', 'Year'], axis='columns', inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.drop([17010, 7734, 47002, 44369, 24720, 50574, 36542, 42611,\n",
    "         22513, 12773, 21501, 2424, 52910, 29735, 43004, 47125], axis='rows', inplace=True)\n",
    "df.drop(df.index[df.EngineSize > 7500], axis='rows', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data, handle categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Brand\"] = df[\"Brand\"].astype(\"category\").cat.codes\n",
    "df[\"Color\"] = df[\"Color\"].astype(\"category\").cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Price\"])\n",
    "y = df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "We start by checking on how good decision trees perform on our dataset.\n",
    "> Grow a decision tree for our training data.  Use a [DecisionTreeRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) from Scikit-Learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# dt = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=30, min_samples_split=2, random_state=42)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now calculate the $R^2$ score on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# r2_train = ...\n",
    "# print(\"r2 train:\", r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_train)\n",
    "r2_train = r2_score(y_train, y_pred)\n",
    "print(\"r2 train:\", r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, such a high score. Almost perfect... Now calculate the cross validation score using a 5-fold cross validation. \n",
    "\n",
    "> Perform a 5-fold cross validation by using  the [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# r2_cv = ...\n",
    "# print(\"r2 cv:\", r2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_cv = np.mean(cross_val_score(dt, X_train, y_train, cv=5, scoring=\"r2\"))\n",
    "print(\"r2 cv:\", r2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our CV-Score looks rather disappointing. How is this behaviour called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further investigate on how our model performs, we plot the so called learning curve. We use the [learning_curve](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.learning_curve.html) function from Scikit-Learn.\n",
    "\n",
    "The learning curve shows the validation and the training score of our model for varying numbers of training samples. It is a nice tool to find out how much we benefit from adding more trianing data and wheter our model suffers from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, we will not benefit much from more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, title):\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Number of training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    \n",
    "    train_sizes = np.linspace(.1, 1.0, 10)\n",
    "    train_sizes, train_scores, cv_scores = learning_curve(\n",
    "        estimator, X, y, cv=5, train_sizes=train_sizes, scoring=\"r2\")\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    cv_scores_mean = np.mean(cv_scores, axis=1)\n",
    "    cv_scores_std = np.std(cv_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.ylim(0.75, 1.01)\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, cv_scores_mean - cv_scores_std,\n",
    "                     cv_scores_mean + cv_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, cv_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    print(\"cross validation r2-score:\", cv_scores_mean[-1])\n",
    "    print(\"training r2-score\", train_scores_mean[-1])\n",
    "    \n",
    "plot_learning_curve(dt, X_train, y_train, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $R^2$ score on the training set is pretty high. We play around with the parameters `max_depth` and `min_samples_split` to close the gap between the training and CV-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_depth\": range(10, 21),\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 6, 7], \n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(dt, parameters, cv=5, scoring=\"r2\")\n",
    "gridSearch.fit(X_test, y_test)\n",
    "\n",
    "print(\"Best score\", gridSearch.best_score_)\n",
    "print(\"Best params\", gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the best decision tree by means of the attribute `best_estimator_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = gridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the learning curve again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(dt, X_train, y_train, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have chosen the optimal hyperparameters for out tree, let's check how good our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine our tree\n",
    "Let us check how our grown decision tree looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", dt.tree_.node_count)\n",
    "print(\"Depth:\", dt.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot our tree (Optional)\n",
    "Scikit-Learn version 0.21 provides a cool new function `plot_tree` which allows us to easily visualize our Decision Tree. To run the following cell, make sure that your Scikit-Learn version is up to date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plot_tree(dt, max_depth=2, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our plot we can see that the first splits were made based on the features with indices 3 and 8. What kind of features are these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature 3:\", X_train.columns[3])\n",
    "print(\"Feature 8:\", X_train.columns[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the features *Horsepower* and *Age* are somehow important. Our estimator stores the importance of each feature in the attribute `feature_importances_`. Note that the values should sum up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot these feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(estimator, X, title, ax=None):\n",
    "    importances = estimator.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    feature_names = X_train.columns.take(indices).tolist()\n",
    "    \n",
    "    plt.subplots(figsize=(15, 5))\n",
    "    plt.title(title)\n",
    "    plt.bar(range(X_train.shape[1]), importances[indices], color=\"b\", align=\"center\")\n",
    "    plt.xticks(range(X_train.shape[1]), feature_names)\n",
    "    plt.xlim([-1, X_train.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "plot_feature_importance(dt, X_train, \"Feature importances extracted from the Decision Tree model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have guessed based on the plot of our tree, the features *Horsepower* and *Age* are the most important ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Let us check if we can beat the score of our model by using a Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fit a [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) and use 10 decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "# rf = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the learning curve as we did with the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(rf, X_train, y_train, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gap between the training and the cross validation score is not as high as with the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still want to run a grid search to tune the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"n_estimators\": [10],\n",
    "    \"max_depth\": range(5, 21),\n",
    "    \"min_samples_split\": [2, 3, 4, 5, 6, 7]\n",
    "}\n",
    "\n",
    "gridSearch = GridSearchCV(rf, parameters, cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "gridSearch.fit(X_test, y_test)\n",
    "\n",
    "print(\"Best score\", gridSearch.best_score_)\n",
    "print(\"Best params\", gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate our model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"r2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(rf, X_train, \"Feature importances extracted from the Random Forest model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a random forest model, the *Mileage* feature gets more weight than the *Age* feature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
