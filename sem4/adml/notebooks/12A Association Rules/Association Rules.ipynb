{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Rule Mining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn does not support association rule learning. Fortunately though, [Sebastian Raschka](https://sebastianraschka.com) (a personal hero of mine) implemented this (and many other cool things) in his library *mlextend*, which aims to be as Scikit-Learn compatible as possible.\n",
    "\n",
    "You can find examples for generating frequent itemsets with apriori [here](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/) and for association rule mining [here](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually\n",
    "But first, we do a little manual calculation. You are given the following dataset of transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [['oats', 'lego', 'teddybear', 'rc car'],\n",
    "                ['oats', 'red coat', 'gloves', 'teddybear', 'doll', 'warm boot'],\n",
    "                ['lego', 'red jelly bag cap', 'rc car', 'doll'],\n",
    "                ['lego', 'oats', 'large red bag', 'gift wrap paper', 'warm boot']]\n",
    "\n",
    "transactions = pd.DataFrame(data={\"Items\":transactions}, index=range(1,5))\n",
    "transactions.index.name = 'Id'\n",
    "\n",
    "with pd.option_context('display.max_colwidth', 80):\n",
    "    print(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculate the support for lego, oats and doll (manunally or by code, your choice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# support_lego = 3/4\n",
    "# support_oats = 3/4\n",
    "# support_doll = 2/4\n",
    "\n",
    "# or with code, for example:\n",
    "support = {}\n",
    "for item in ['lego', 'oats', 'doll']:\n",
    "    support[item] = transactions.Items.map(lambda x: item in x).sum() / transactions.shape[0] # support of 'lego'\n",
    "support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculate the confidence of `['lego', 'oats'] -> ['teddybear']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confidence_lego_oats-teddybear = 0.25 / 0.5\n",
    "0.25 / ( transactions.Items.map(lambda x: 'lego' in x and 'oats' in x).sum() / transactions.shape[0]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the Apriori algorithm and find the frequent item sets with a minimum support of 0.5 and minimum confidence of 0.75. Here is the dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', 80):\n",
    "    print(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 1**: Generate frequent item sets satisfying the support threshold (hint: there are 6 itemsets of length 1 and 4 itemsets of length 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the following code to show the solution. We will see how to use this library in a minute.\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(transactions.Items.values.tolist())\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "freq_itemsets = apriori(df, use_colnames=True, min_support=0.5)\n",
    "freq_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Step 2**: Extract rules from frequent item sets satisfying the confidence threshold (hint: there are three itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true,
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "There are 8 candidates: From all 4 itemsets with two items, generate the two possibilities.\n",
    "\n",
    "From these 8 candidates, 4 have a confidence of 0.5/0.75 which is below the threshold and 4 have a confidence of 0.5/0.5 which is above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the following code to show the solution\n",
    "association_rules(freq_itemsets, metric='confidence', min_threshold=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, enough manual calculation with a toy example for today. Let's work with a bigger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated\n",
    "You are given some transactional data about purchases in a supermarket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('acostasg.csv')\n",
    "transactions.columns = ['Date', 'Transaction', 'Item']\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a kind of placeholder item *'all- purpose'* (notice the space after the dash) in the data which appears multiple times in some transactions. \n",
    "> Remove rows with this item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions = transactions[transactions.Item != 'all- purpose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by transaction ID\n",
    "We group the data by transaction id and aggregate purchases into a list (the Date is constant for s single transaction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.groupby('Transaction').agg({'Date':lambda x: x.iloc[0] ,'Item':list})\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate size for each transaction\n",
    "We also calculate the size for each transaction.\n",
    "> `map` the function `len` on each row of the *Item* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#transactions['Size'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions['Size'] = transactions['Item'].map(len)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mlxtend library offers a function to turn a list of transactions into the required binary transaction format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_binary = te.fit_transform(transactions.Item)\n",
    "\n",
    "df = pd.DataFrame(te_binary, columns=te.columns_)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Rule Mining\n",
    "> Generate frequent itemsets with a minimum support of 0.05. Look at the examples linked above or given in the solutions of the toy example for hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#freq_itemsets = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_itemsets = apriori(df, min_support=0.05, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now extract all association rules with a confidence threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "#rules = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules = association_rules(freq_itemsets, metric='confidence', min_threshold=0.5)\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Sort this so that the rules with the highest lift are at the top and print the top ten rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "solution2": "hidden",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules.sort_values('lift', ascending=False).head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a list of rules that are interesting (support >= 0.05), trustworthy (confidence >= 0.5) and are ordered by association strength (lift) between antecedents and consequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us display our rule set with the three measures support, confidence and lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10, 8))\n",
    "plt.scatter(rules.support, rules.confidence, c=rules.lift, s=5)\n",
    "plt.xlabel('Support')\n",
    "plt.ylabel('Confidence')\n",
    "plt.title('Scatter Plot for Support vs. Confidence vs. Lift')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter the rules the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.query('support > 0.05 and confidence > 0.9 and lift > 1.3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ilias Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now filter for the rules in the top right corner (support greater than 0.2 and confidence greater than 0.7). What do these rules have in common? Answer the question on ILIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's look at the rules which have a lift greater than 1.6. Are these rules interesting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the topic of Association Rules!"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "0.8.6"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
