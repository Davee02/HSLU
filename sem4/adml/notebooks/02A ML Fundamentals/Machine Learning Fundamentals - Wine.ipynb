{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Fundamentals\n",
    "\n",
    "Today we will implement two simple content-based recommender systems. During the semester we will have a lecture on recommender systems where we look in depth about content-based and collaborative filtering recommender systems.\n",
    "\n",
    "The main goal of this exercise is to get an understanding why similarities and normalization are very important for Machine Learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import skimage\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - Simple recommender system for wine based on similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We move now from cars to wine.\n",
    "On Kaggle there exists a popular [dataset](https://www.kaggle.com/zynicide/wine-reviews) which consists of 130'000 wine reviews. We want to build a recommender system that recommends us a wine based on its description. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winemag-data-10k.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will check if the dataset contains any duplicates. And since the dataset contains duplicates, we will remove them and check again for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dataset contains duplicates: %s' % df.duplicated().any())\n",
    "print('len dataset: %s' % str(len(df)))\n",
    "df.drop_duplicates(inplace=True)\n",
    "print('dataset contains duplicates (after cleaning): %s' % df.duplicated().any())\n",
    "print('len dataset (after cleaning): %s' % str(len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the text in the dataset, both for the description and the title contains upper and lower case letters, it is good to convert it to a similar format, such as both to lower case. This is specifically needed for the next step, where we will remove all of the stopwords according to a dictionary. If we would not convert the text to lowercase, we might miss removing some of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.lower()\n",
    "df['title'] = df['title'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the description by tokenizing all the words and then applying lemmatization and stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "    \n",
    "def normalize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    result = [lemmatize_stemming(token) for token in tokens \n",
    "              if token not in stop_words and len(token) > 3]\n",
    "    return result\n",
    "\n",
    "df[\"normalized\"] = df.description.apply(lambda x: normalize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataset looks like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again take some of our training data as our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:9960]\n",
    "test = df.iloc[9960:]\n",
    "\n",
    "X_train = train[\"normalized\"].values\n",
    "X_test = test[\"normalized\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate our similarities, we only consider the normalized descriptions. For the first wine in our training set it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare two wines, we use the jaccard similarity.\n",
    "> Implement the jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    similarity = 0\n",
    "    # START YOUR CODE\n",
    "    \n",
    "    # END YOUR CODE\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return float(len(s1.intersection(s2))) / float(len(s1.union(s2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, the following cell should run without an error.\n",
    "> Verify your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_similarity = 0.05405405405405406\n",
    "similarity = jaccard_similarity(X_train[0], X_train[1])\n",
    "\n",
    "np.testing.assert_equal(similarity, expected_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize similarities\n",
    "We can visualize the similarity between the wines using a heatmeap. Let us show how similar the first 40 wines are. The darker the box in the heatmap, the more similar they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = np.asarray([[jaccard_similarity(p1, p2) \n",
    "                  for p1 in X_train[0:40]] \n",
    "                    for p2 in X_train[0:40]])\n",
    "fig, ax = plt.subplots(figsize=(18,12))    \n",
    "ax = sns.heatmap(dm, linewidth=0.5, cmap=\"YlGnBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find most similar wine\n",
    "> Now implement the `nearest_neighbor` function, which returns the index of the most similar wine and the similarity value. *Hint: We use now a similarity measure instead of a distance measure*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(wine, wines):\n",
    "    idx = -1\n",
    "    similarity = -1\n",
    "    # START YOUR CODE\n",
    "    \n",
    "    # END YOUR CODE\n",
    "    return idx, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Click on the dots to display the solution*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor(wine, wines):\n",
    "    similarities = np.array([jaccard_similarity(wine, w) for w in wines])\n",
    "    # as we are dealing with similarities now, we have to find the most similar wine\n",
    "    similarity = np.max(similarities)\n",
    "    idx = np.argmax(similarities)\n",
    "    return idx, similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is correct, the following cell should run without an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = X_test[0]\n",
    "\n",
    "expected_similarity = 0.30303030303030304\n",
    "idx, similarity = nearest_neighbor(wine, X_train)\n",
    "np.testing.assert_equal(similarity, expected_similarity)\n",
    "\n",
    "most_similar = train.iloc[[idx]]\n",
    "\n",
    "print(\"Most similar wine: {}\".format(most_similar.title.values[0]))\n",
    "print(\"Similarity: \", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play around with our recommender system\n",
    "We can now use our recommender system to get a wine recommendation based on its description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@widgets.interact(wine_title=widgets.Dropdown(options=sorted(test.title), description=\"Wine title\"))\n",
    "def recommend(wine_title):\n",
    "    wine = X_test[test[\"title\"] == wine_title][0]\n",
    "    idx, similarity = nearest_neighbor(wine, X_train)\n",
    "    \n",
    "    most_similar = train.iloc[[idx]]\n",
    "    print(\"Most similar wine: '{}' with a similarity of {:2f}\".format(most_similar.title.values[0], similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now answer the ILIAS quiz **Machine Learning Fundamentals**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
